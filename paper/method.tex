% to-do
% -----
% - outline full paper (see notes in hardcover book 2012-09-12)
% - fill out intro section
% - fill out data section
% - fill out method section
% - decide on best ``functional tests'' to convince any skeptical reader
% - choose examples

\documentclass[12pt,preprint,dvipdf]{aastex}
\newcounter{address}
\newcommand{\project}[1]{\textsl{#1}}
\newcommand{\units}[1]{\mathrm{#1}}
\renewcommand{\mag}{\units{mag}}
\renewcommand{\arcmin}{\units{arcmin}}
\newcommand{\rfifty}{r_{50}}
\newcommand{\rninety}{r_{90}}
\newcommand{\conc}{C}

\begin{document}
\title{
       Measuring galaxies with very large angular sizes.
      }
\author{
        David Mykytyn\altaffilmark{\ref{CCPP}},
        Dustin Lang\altaffilmark{\ref{CMU}},
        Ekta Patel\altaffilmark{\ref{CCPP}},
        David W. Hogg\altaffilmark{\ref{CCPP},\ref{MPIA},\ref{email}}
       }
\setcounter{address}{1}
\altaffiltext{\theaddress}{\stepcounter{address}\label{CCPP} Center
  for Cosmology and Particle Physics, Department of Physics, New York
  University, 4 Washington Place, New York, NY 10003}
\altaffiltext{\theaddress}{\stepcounter{address}\label{CMU} Carnegie
  Mellon University}
\altaffiltext{\theaddress}{\stepcounter{address}\label{MPIA}
  Max-Planck-Institut f\"ur Astronomie, K\"onigstuhl 17, D-69117
  Heidelberg, Germany}
\altaffiltext{\theaddress}{\stepcounter{address}\label{email} To whom
  correspondence should be addressed: \texttt{david.hogg@nyu.edu}}

\begin{abstract}
The measurement of galaxies with large angular sizes is challenging,
and has rarely been done well in automated settings.  Issues include
that the galaxies overlap field boundaries, overlap foreground stars,
and show detailed and confusing internal structure at high
signal-to-noise.  We take a generative modeling or likelihood approach
to making measurements of the galaxies, but with the likelihood
modified for robustness.  We show that we get reliable measurements
for very large galaxies ($>1~\arcmin$ in diameter) in the
\project{Sloan Digital Sky Survey} imaging data.
\end{abstract}

\section{Introduction}

\section{Data and input catalogs}
The primary source of for the input catalog was the Third Reference Catalog of Bright Galaxies (RC3) from which we pulled all objects which had an angular diameter equal to or greater than 2 arcminutes as measured in the apparent major isophotal diameter at the surface brightness level $\mu_B = 25,0$ B-mag per square arcsecond. Next, we checked the NASA-Sloan Atlas (NSA) for any objects of significant size that were also not in RC3. The cut was for objects with a 50\% light radius of the SERSIC fit greater than 30 arcseconds. The objects were then examined by eye to determine which ones were actual large galaxies, and which were errors in the NSA. Example errors included stars causing saturation, interstellar medium, and nebulae. We also checked the 2MASS Large Galaxy Atlas but no galaxies of the correct size not already in RC3 were found. The only objects found were either not in the Sloan Survey, or were globular clusters. The cut for 2MASS was based on the isophotal fiduciary radius in the K-band, which was checked to a radius of 1 arcminute.


\section{Tractor}
Models: Write about the types of models used?? Different galaxies types etc?
The Tractor functions first by building a model, using initial parameter data that is supplied. Next, it takes the derivative of that in parameter space. It performs a least square optimization of that, attempting to minimize the difference between the data and the model. Once the best direction is found, it makes a series of increasings steps (how is step size determined??) until the $\chi^2$ stops improving (I think this is imprecise/wrong) Finally the parameters are updated in that direction. The tractor is capable of freezing certain parameters, so that they are excluded from the optimization. 
The iteratively-reweighted least squares process is used to update the
inverse variances after each iteration of optimization. The formula
used is: \begin{equation} \frac{1}{\sigma}=\frac{Q^2}{Q^2+\chi^2}
\end{equation}
where $Q$ is the number of ``sigma'' at which the residual saturates. $Q$ for these fittings was chosen to be 5. (Find out why)

\section{Method}
When given an RA and a DEC and a radius, the program searches the SDSS data for fields which overlap anywhere in that space. It downloads all those fields, in all bands, as fits files, and then imports them into the program as arrays. The initial inverse variances are also downloaded from Sloan.
Saturated pixels from the SDSS images were masked and then a binary dilation with three iterations was applied. (more details needed here?)

For the purpose of measuring and optimizing on a single galaxy at a
time, all other objects were removed from within a circle centered on
the galaxy center and radius, both given by the RC3 catalog (using the major isophotal diameter)
(which radius?) for that particular catalog. This was done rather than
working within the SDSS catalog because SDSS frequently splits up large
galaxies into numerous small ones and so it was much easier to simply
start over with a single galaxy. As initialization, that galaxy was
given magnitudes of 15 in every band and a radius given by the RC3
catalog.

In order to deal with the problems of stars that overlap with the
galaxy which we are interested in, we decided to mask them out. The
stars were found using the data in the TYCHO2 star catalog (Add tycho2 cite)
 using the spherematch function of astrometry.net. The stars were masked out to a
radius of
\begin{equation}
\theta_{\mathrm{exclude}} = \max(25, 25\,2^{[11\,\mag-V]})
\end{equation}
where $V$ is the visual magnitude given by TYCHO2.
(I'm not sure why these values, I got them from Dustin)



We start the fitting with an exponential galaxy and then optimize
simply that galaxy six times. Following that, we switch to a composite
galaxy, with both exponential and deVaucouleur components. These
components are free to vary separately in order to best fit the
data. This new composite galaxy is also optimized six times by itself.

In order to measure the half-light radius $\rfifty$, the 90 percent
radius $\rninety$ and the concentration parameter $\conc\equiv
\rninety/\rfifty$, we took the model of the galaxy that had been
optimized and places it in an empty frame within the tractor. Next,
over a series of increasing intervals of radii we summed up the total
flux within the circles and then interpolated to find $\rfifty$ and $\rninety$. We used sixty-four radii equally spaced in pixel logarithms from zero to half the height of the image.
Exceptional cases were flagged for later review if $\rfifty$ was not between the deVaucouleur and exponential radii for that galaxy, and concentration was flagged as incorrect if $\frac{1}{\conc}$ was not between .29 and .46. (We are not getting these numbers, mention in discussion?) TODO: Add citation to paper for these numbers

For instance, the galaxy M81 had too large of a radius in RC3 in order to run properly so it was manually reduced so as to fit into the memory of the machine. The scaling factors used were if the number of fields were between ten and twenty, a factor of two scaling. Four was used for between twenty and forty, and eight was used for between forty and eighty. Above eighty, the galaxy was skipped. (Put into table?) Another example is M51a and M51b, which were simultaneously fit in order to ensure that the fit measured both galaxies simultaneously. 

All data that was flagged for review was reviewed by examination of the flipbook for that galaxy, in order that changes could be made to the initialization for that galaxy, or if the expected galaxy was nonexistent and therefore a mistake in a prior catalog, removed entirely from the catalog. 



Citations: Figure out how to actually cite these:
http://www.astro.ku.dk/~erik/Tycho-2/letter.pdf  - TYCHO-2

\section{Selected results}

\section{Discussion}

\end{document}

